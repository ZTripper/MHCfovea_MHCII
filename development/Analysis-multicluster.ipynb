{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json, random, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logomaker as lm\n",
    "from statannot import add_stat_annotation\n",
    "from CAMInterp import CAMInterp\n",
    "from MHCInterp import MHCInterp\n",
    "from scipy.stats import ttest_ind, t\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataframe_dir = ''\n",
    "allele_expansion_dir = ''\n",
    "summarization_dir = '' # the output directory of Analysis-summarization.ipynb\n",
    "cam_analysis_dir = '' # the output directory of Analysis-ScoreCAM.ipynb\n",
    "performance_dir = '' # the working directory of Analysis-performance.ipynb \n",
    "output_dir = ''\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WelchTest(x1, x2):\n",
    "    np.set_printoptions(precision=2)\n",
    "    n1 = x1.size\n",
    "    n2 = x2.size\n",
    "    m1 = np.mean(x1)\n",
    "    m2 = np.mean(x2)\n",
    "    v1 = np.var(x1, ddof=1)\n",
    "    v2 = np.var(x2, ddof=1)\n",
    "    \n",
    "    pooled_se = np.sqrt(v1 / n1 + v2 / n2)\n",
    "    delta = m1-m2\n",
    "    \n",
    "    tstat = delta / pooled_se\n",
    "    df = (v1 / n1 + v2 / n2)**2 / (v1**2 / (n1**2 * (n1 - 1)) + v2**2 / (n2**2 * (n2 - 1)))\n",
    "    \n",
    "    # two side t-test\n",
    "    p = 2 * t.cdf(-abs(tstat), df)\n",
    "    \n",
    "    # upper and lower bounds\n",
    "    lb = delta - t.ppf(0.975,df)*pooled_se \n",
    "    ub = delta + t.ppf(0.975,df)*pooled_se\n",
    "    \n",
    "    # stat dict\n",
    "    stat_dict = {\n",
    "        'n': [n1,n2],\n",
    "        'm': [m1,m2],\n",
    "        'sd': [np.sqrt(v1), np.sqrt(v2)],\n",
    "        'df': df,\n",
    "        'psd': pooled_se,\n",
    "        'tstat': tstat,\n",
    "        'delta': delta,\n",
    "        'pvalue': p,\n",
    "        'lb': lb,\n",
    "        'ub': ub\n",
    "    }\n",
    "  \n",
    "    return stat_dict\n",
    "\n",
    "\n",
    "def PrintStatDF(df):\n",
    "    temp_df = pd.DataFrame(index=['n','m','sd','df','psd','tstat','pvalue','lb','ub'])\n",
    "    for idx, row in df.iterrows():\n",
    "        temp_df['{}_{}'.format(row['pair1'], idx)] = [\n",
    "            row['n'][0],\n",
    "            row['m'][0],\n",
    "            row['sd'][0],\n",
    "            row['df'],\n",
    "            row['psd'],\n",
    "            row['tstat'],\n",
    "            row['pvalue'],\n",
    "            row['lb'],\n",
    "            row['ub']\n",
    "        ]\n",
    "\n",
    "        temp_df['{}_{}'.format(row['pair2'], idx)] = [\n",
    "            row['n'][1],\n",
    "            row['m'][1],\n",
    "            row['sd'][1],\n",
    "            row['df'],\n",
    "            row['psd'],\n",
    "            row['tstat'],\n",
    "            row['pvalue'],\n",
    "            row['lb'],\n",
    "            row['ub']\n",
    "        ]\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hla = 'B'\n",
    "\n",
    "# MHC sequences\n",
    "mhc_seq_filename = '../data/MHCI_res182_seq.json'\n",
    "mhc_seq_dict = json.load(open(mhc_seq_filename, 'r'))\n",
    "\n",
    "# dataset\n",
    "train_df = pd.read_csv('%s/train_hit.csv'%dataframe_dir, index_col=0)\n",
    "valid_df = pd.read_csv('%s/valid.csv'%dataframe_dir, index_col=0)\n",
    "test_df = pd.read_csv('%s/benchmark.csv'%dataframe_dir, index_col=0)\n",
    "\n",
    "# hyper-motif cluster\n",
    "nside_df = pd.read_csv('%s/%s_NsideDF.csv'%(summarization_dir, hla), index_col=0)\n",
    "cside_df = pd.read_csv('%s/%s_CsideDF.csv'%(summarization_dir, hla), index_col=0)\n",
    "\n",
    "# MHCInterp\n",
    "submotif_len = 4\n",
    "position_dict = json.load(open('%s/ResidueSelection.json'%cam_analysis_dir, 'r'))\n",
    "\n",
    "mhc_motif_dict = dict()\n",
    "for sub_dir in os.listdir(allele_expansion_dir):\n",
    "    d = np.load('{}/{}/motif.npy'.format(allele_expansion_dir, sub_dir), allow_pickle=True)[()]\n",
    "    mhc_motif_dict = {**mhc_motif_dict, **d}\n",
    "\n",
    "tmp = 'tmp/'\n",
    "if not os.path.isdir(tmp):\n",
    "    os.mkdir(tmp)\n",
    "\n",
    "mhc_interp = MHCInterp(mhc_seq_dict, mhc_motif_dict, submotif_len, position_dict, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multicluster_groups = list()\n",
    "minor_frequency = 0.1\n",
    "minimal_num = 25\n",
    "\n",
    "for hla in ['A', 'B', 'C']:\n",
    "    Nside_group_df = pd.read_csv('%s/%s_NsideGroupCount.csv'%(summarization_dir, hla), index_col=0)\n",
    "    Cside_group_df = pd.read_csv('%s/%s_CsideGroupCount.csv'%(summarization_dir, hla), index_col=0)\n",
    "    \n",
    "    threshold = Nside_group_df.sum(axis=0)*minor_frequency\n",
    "    threshold[threshold >= minimal_num] = minimal_num\n",
    "    temp_df = (Nside_group_df - threshold > 0).sum(axis=0)\n",
    "    multicluster_groups += temp_df[temp_df > 1].index.tolist()\n",
    "    \n",
    "    threshold = Cside_group_df.sum(axis=0)*minor_frequency\n",
    "    threshold[threshold > minimal_num] = minimal_num\n",
    "    temp_df = (Cside_group_df - threshold > 0).sum(axis=0)\n",
    "    multicluster_groups += temp_df[temp_df > 1].index.tolist()\n",
    "\n",
    "multicluster_groups = sorted(list(set(multicluster_groups)))\n",
    "print(multicluster_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLA group polymorphism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group dict\n",
    "group_dict = dict()\n",
    "for allele in mhc_seq_dict.keys():\n",
    "    group = allele.split(':')[0]\n",
    "    if group_dict.get(group):\n",
    "        group_dict[group].append(allele)\n",
    "    else:\n",
    "        group_dict[group] = [allele]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group polymorphism df\n",
    "positions = list(range(182))\n",
    "group_polymorphism_dict = dict()\n",
    "allele_num_dict = dict()\n",
    "for group in group_dict.keys():\n",
    "    alleles = group_dict[group]\n",
    "    allele_num_dict[group] = len(alleles)\n",
    "    seqlogo_df = mhc_interp._mhc_seqlogo(alleles, positions)\n",
    "    polymorphism = -(seqlogo_df*np.log(seqlogo_df)).sum(axis=1).values\n",
    "    group_polymorphism_dict[group] = polymorphism\n",
    "group_polymorphism_df = pd.DataFrame(group_polymorphism_dict).T\n",
    "group_polymorphism_df = group_polymorphism_df.rename(columns={i:positions[i] for i in group_polymorphism_df.columns})\n",
    "\n",
    "# allele number\n",
    "group_polymorphism_df['num'] = pd.Series(allele_num_dict)\n",
    "\n",
    "# mean of positions\n",
    "res34_pos = [6, 8, 23, 44, 58, 61, 62, 65, 66, 68, 69, 72, 73, 75, 76, 79, 80, 83, 94,\n",
    "             96, 98, 113, 115, 117, 142, 146, 149, 151, 155, 157, 158, 162, 166, 170]\n",
    "group_polymorphism_df['all'] = group_polymorphism_df[positions].mean(axis=1)\n",
    "group_polymorphism_df['important'] = group_polymorphism_df[mhc_interp.position_dict['selected']].mean(axis=1)\n",
    "group_polymorphism_df['multicluster'] = 'mono-cluster'\n",
    "group_polymorphism_df.loc[multicluster_groups, 'multicluster'] = 'multi-cluster'\n",
    "##group_polymorphism_df['34-residue'] = group_polymorphism_df[res34_pos].mean(axis=1)\n",
    "group_polymorphism_df.to_csv('%s/GroupPolymorphism.csv'%output_dir)\n",
    "group_polymorphism_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp df for seaborn\n",
    "temp = list()\n",
    "for idx, row in group_polymorphism_df.iterrows():\n",
    "    temp.append({'group': idx, 'type': 'all', 'multicluster': row['multicluster'], 'polymorphism': row['all']})\n",
    "    temp.append({'group': idx, 'type': 'important', 'multicluster': row['multicluster'], 'polymorphism': row['important']})\n",
    "    ##temp.append({'group': idx, 'type': '34-residue', 'multicluster': row['multicluster'], 'polymorphism': row['34-residue']})\n",
    "temp = pd.DataFrame(temp)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# barplot\n",
    "fig, ax = plt.subplots(3, figsize=(8,12), dpi=600)\n",
    "hla_list = ['A', 'B', 'C']\n",
    "for i in range(len(hla_list)):\n",
    "    temp_hla = hla_list[i]\n",
    "    groups = [j for j in temp['group'] if temp_hla in j]\n",
    "    sns.barplot(x='group', y='polymorphism', hue='type', data=temp[temp['group'].isin(groups)], ax=ax[i])\n",
    "    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation = 90)\n",
    "    ax[i].set_title(temp_hla)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('%s/PolyCompBarplot.png'%output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# boxplot\n",
    "data = temp\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(6,3), dpi=600)\n",
    "sns.boxplot(x='type', y='polymorphism', hue='multicluster', data=data, ax=ax)\n",
    "\n",
    "box_pairs = [(('all', 'mono-cluster'), ('all', 'multi-cluster')),\n",
    "             (('important', 'mono-cluster'), ('important', 'multi-cluster'))]\n",
    "test_results = add_stat_annotation(ax=ax, data=data, x='type', y='polymorphism', hue='multicluster',\n",
    "                                   box_pairs=box_pairs, comparisons_correction=None,\n",
    "                                   test='t-test_ind', stats_params={'equal_var': False},\n",
    "                                   text_format='star', loc='outside',\n",
    "                                   fontsize=mhc_interp.fontsize, linewidth=0.3,\n",
    "                                   line_offset_to_box=0.05)\n",
    "\n",
    "stat_dict_list = list()\n",
    "for p1, p2 in box_pairs:\n",
    "    stat_dict = WelchTest(data[(data['type']==p1[0]) & (data['multicluster']==p1[1])]['polymorphism'],\n",
    "                          data[(data['type']==p2[0]) & (data['multicluster']==p2[1])]['polymorphism'])\n",
    "    stat_dict['pair1'] = '{}: {}'.format(p1[0], p1[1])\n",
    "    stat_dict['pair2'] = '{}: {}'.format(p1[0], p2[1])\n",
    "    stat_dict_list.append(stat_dict)\n",
    "\n",
    "_ = ax.legend(title='HLA groups')\n",
    "_ = ax.set_xlabel(None)\n",
    "_ = ax.set_xticklabels(['all positions (182 a.a.)', 'important positions (42 a.a.)'])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('%s/PolyCompBoxplot.png'%output_dir)\n",
    "\n",
    "stat_df = PrintStatDF(pd.DataFrame(stat_dict_list))\n",
    "stat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unobserved alleles within multi-cluster groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = json.load(open('%s/without_mixmhcpred/AlleleMetrics.json'%performance_dir, 'r'))\n",
    "\n",
    "target = \"Unobserved\" # Rare or Unobserved\n",
    "\n",
    "unobserved_alleles = ['A*24:07', 'A*33:03', 'A*34:01', 'A*34:02', 'A*36:01', 'B*07:04', 'B*15:10', 'B*35:07',\n",
    "                      'B*38:02', 'B*40:06', 'B*55:01', 'B*55:02', 'C*03:02', 'C*04:03', 'C*08:01', 'C*14:03']\n",
    "\n",
    "multicluster_groups = list(group_polymorphism_df[group_polymorphism_df['multicluster']=='multi-cluster'].index)\n",
    "\n",
    "target_alleles = list()\n",
    "for allele in unobserved_alleles:\n",
    "    group = allele.split(':')[0]\n",
    "    if group in multicluster_groups:\n",
    "        target_alleles.append(allele)\n",
    "\n",
    "other_alleles = list(set(unobserved_alleles) - set(target_alleles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = ['AUC', 'AP']\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for metrics in metrics_list:\n",
    "    temp = pd.DataFrame(pf[metrics])\n",
    "    temp = temp[(temp['method']=='MHCfovea') & (temp['allele'].isin(alleles))]\n",
    "    temp['multicluster'] = 'mono-cluster'\n",
    "    temp.loc[temp['allele'].isin(target_alleles), 'multicluster'] = 'multi-cluster'\n",
    "    temp['metrics'] = metrics\n",
    "    data = pd.concat([data, temp], axis=0, ignore_index=True)\n",
    "\n",
    "data = data.sort_values(by=['metrics', 'allele'])\n",
    "data.to_csv('%s/GroupUnobserved.csv'%output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(6,3), dpi=600)\n",
    "stat_dict_list = list()\n",
    "for i in range(len(metrics_list)):\n",
    "    metrics = metrics_list[i]\n",
    "    temp_data = data[data['metrics']==metrics]\n",
    "    \n",
    "    sns.boxplot(x='multicluster', y='value', data=temp_data, ax=ax[i])\n",
    "    ax[i].set_yticks([i for i in ax[i].get_yticks() if i <= 1.0])\n",
    "    \n",
    "    box_pairs = [('mono-cluster', 'multi-cluster')]\n",
    "    test_results = add_stat_annotation(ax=ax[i], data=temp_data, x='multicluster', y='value',\n",
    "                                       box_pairs=box_pairs, comparisons_correction=None,\n",
    "                                       test='t-test_ind', stats_params={'equal_var': False},\n",
    "                                       text_format='star', loc='outside',\n",
    "                                       fontsize=mhc_interp.fontsize, linewidth=0.3,\n",
    "                                       line_offset_to_box=0.05)\n",
    "    \n",
    "    for p1, p2 in box_pairs:\n",
    "        stat_dict = WelchTest(temp_data[temp_data['multicluster']==p1]['value'],\n",
    "                              temp_data[temp_data['multicluster']==p2]['value'])\n",
    "        stat_dict['pair1'] = '{}: {}'.format(metrics, p1)\n",
    "        stat_dict['pair2'] = '{}: {}'.format(metrics, p2)\n",
    "        stat_dict_list.append(stat_dict)\n",
    "    \n",
    "    ax[i].set_xlabel(None)\n",
    "    ax[i].set_ylabel(metrics)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('{}/MultiClusterComp{}.png'.format(output_dir, target))\n",
    "stat_df = PrintStatDF(pd.DataFrame(stat_dict_list))\n",
    "stat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of HLA group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqlogo_plot(self, seqlogo_df, positions, ax, highlight_pos_dict=dict(),\n",
    "                 ylim=1, title=None, turn_off_label=False):\n",
    "    logo = lm.Logo(seqlogo_df, color_scheme='skylign_protein', ax=ax)\n",
    "    \n",
    "    _ = ax.set_ylim(0, ylim)\n",
    "    _ = ax.set_xticks(range(len(positions)))\n",
    "    _ = ax.set_xticklabels([i+1 for i in positions], rotation=90)\n",
    "    _ = ax.set_title(title)\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(self.fontsize)\n",
    "    for item in ax.get_xticklabels():\n",
    "        item.set_fontsize(self.fontsize-3)\n",
    "    \n",
    "    _ = ax.set_yticks([])\n",
    "    _ = ax.set_yticklabels([])\n",
    "    if turn_off_label:\n",
    "        _ = ax.set_xticks([])\n",
    "        _ = ax.set_xticklabels([])\n",
    "        _ = ax.set_title(None)\n",
    "        \n",
    "    if highlight_pos_dict != dict():\n",
    "        for color, highlight_pos in highlight_pos_dict.items():\n",
    "            highlight_pos = sorted(set(highlight_pos) & set(positions))\n",
    "            for pos in highlight_pos:\n",
    "                logo.highlight_position(p=positions.index(pos), color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hla = 'B'\n",
    "nside_df = pd.read_csv('%s/%s_NsideDF.csv'%(summarization_dir, hla), index_col=0)\n",
    "cside_df = pd.read_csv('%s/%s_CsideDF.csv'%(summarization_dir, hla), index_col=0)\n",
    "\n",
    "# add hla group\n",
    "train_df['hla_group'] = train_df.mhc.apply(lambda x: x.split(':')[0])\n",
    "valid_df['hla_group'] = valid_df.mhc.apply(lambda x: x.split(':')[0])\n",
    "test_df['hla_group'] = test_df.mhc.apply(lambda x: x.split(':')[0])\n",
    "nside_df['hla_group'] = [x.split(':')[0] for x in nside_df.index]\n",
    "nside_df = nside_df[['label', 'select_label', 'hla_group']]\n",
    "cside_df['hla_group'] = [x.split(':')[0] for x in cside_df.index]\n",
    "cside_df = cside_df[['label', 'select_label', 'hla_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build group df of training and testing dataset\n",
    "group = 'B*56'\n",
    "side = 'C'\n",
    "\n",
    "if side == 'N':\n",
    "    side_df = nside_df\n",
    "else:\n",
    "    side_df = cside_df\n",
    "\n",
    "alleles = list(set(list(train_df[train_df['hla_group']==group].mhc.unique()) + list(test_df[test_df['hla_group']==group].mhc.unique())))\n",
    "\n",
    "group_dict = list()\n",
    "for allele in alleles:\n",
    "    try:\n",
    "        label = side_df.loc[allele]['label']\n",
    "    except:\n",
    "        label = -1\n",
    "    group_dict.append({\n",
    "        'allele': allele,\n",
    "        'train_num': train_df[train_df['mhc']==allele].shape[0],\n",
    "        'valid_num': valid_df[(valid_df['mhc']==allele) & (valid_df['source'].isin(['MS', 'assay']))].shape[0],\n",
    "        'test_num': test_df[(test_df['mhc']==allele) & (test_df['source']=='MS')].shape[0],\n",
    "        'label': label\n",
    "    })\n",
    "group_df = pd.DataFrame(group_dict)\n",
    "group_df.sort_values(by='allele')\n",
    "\n",
    "print(group_df)\n",
    "print('-----------------------------')\n",
    "print('label counts')\n",
    "print(group_df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important positions\n",
    "positions = mhc_interp.position_dict['selected']\n",
    "\n",
    "# backgroup seqlogo_df\n",
    "alleles = side_df[side_df['select_label'] != -1].index.tolist()\n",
    "hla_seqlogo_df = mhc_interp._mhc_seqlogo(alleles, positions)\n",
    "\n",
    "# clusters\n",
    "clusters = sorted(list(side_df[side_df['hla_group']==group].label.unique()))\n",
    "\n",
    "print('Clusters: ', clusters)\n",
    "print('Value counts of clusters')\n",
    "print(side_df[side_df['hla_group']==group].label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# B15\n",
    "target_clusters = [2,3,4]\n",
    "highlight_pos_dict = {'#f2f2f2': [44,61,62,64,65,66,68,69,70]}\n",
    "'''\n",
    "# B56\n",
    "target_clusters = [2,3,4]\n",
    "highlight_pos_dict = {'#f2f2f2': [93,94,96,97,108,113,115]}\n",
    "\n",
    "figfile = '%s/MultiCluster_%s%s.png'%(output_dir, group[0], group[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots(len(target_clusters), 2, figsize=(6, len(target_clusters)*1.5), dpi=600,\n",
    "                       gridspec_kw={'width_ratios': [1, 5]})\n",
    "\n",
    "for i in range(len(target_clusters)):\n",
    "    cluster = target_clusters[i]\n",
    "    temp_alleles = list(side_df[(side_df['hla_group']==group) & (side_df['label']==cluster)].index)\n",
    "    num = len(temp_alleles)\n",
    "    \n",
    "    # hyper motif of a specific group\n",
    "    mhc_interp._motif_plot(temp_alleles, side, ax[i][0], turn_off_label=True)\n",
    "    \n",
    "    # allele signature of a specific group\n",
    "    group_seqlogo_df = mhc_interp._mhc_seqlogo(temp_alleles, positions)\n",
    "    group_seqlogo_df = group_seqlogo_df - hla_seqlogo_df\n",
    "    group_seqlogo_df[group_seqlogo_df > 0] = 1\n",
    "    group_seqlogo_df[group_seqlogo_df < 0] = 0\n",
    "    \n",
    "    # allele signature of a corresponding cluster\n",
    "    temp_alleles = list(side_df[side_df['select_label']==cluster].index)\n",
    "    cluster_seqlogo_df = mhc_interp._mhc_seqlogo(temp_alleles, positions)\n",
    "    cluster_seqlogo_df = cluster_seqlogo_df - hla_seqlogo_df\n",
    "    cluster_seqlogo_df[cluster_seqlogo_df < 0] = 0\n",
    "    \n",
    "    # highlight\n",
    "    seqlogo_df = group_seqlogo_df * cluster_seqlogo_df\n",
    "    \n",
    "    seqlogo_plot(mhc_interp, seqlogo_df, positions, ax[i][1], highlight_pos_dict=highlight_pos_dict,\n",
    "                 ylim=1, turn_off_label=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(figfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
